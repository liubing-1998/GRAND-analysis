ax = self.anisotropic_diffusion_g(x)
# ax = self.anisotropic_diffusion_g_without_distance(x)
if not self.opt['no_alpha_sigmoid']:
  alpha = torch.sigmoid(self.alpha_train)
else:
  alpha = self.alpha_train
f = alpha * ax
跑了一半，电脑关机停掉了，5.txt从新跑了
2023/08/10 05:59:08 PM {'use_cora_defaults': False, 'dataset': 'Cora', 'data_norm': 'rw', 'self_loop_weight': 1.0, 'use_labels': False, 'geom_gcn_splits': False, 'num_splits': 2, 'label_rate': 0.5, 'planetoid_split': False, 'hidden_dim': 80, 'fc_out': False, 'input_dropout': 0.5, 'dropout': 0.046878964627763316, 'batch_norm': False, 'optimizer': 'adamax', 'lr': 0.022924849756740397, 'decay': 0.00507685443154266, 'epoch': 100, 'alpha': 1.0, 'alpha_dim': 'sc', 'no_alpha_sigmoid': False, 'beta_dim': 'sc', 'block': 'constant', 'function': 'laplacian', 'use_mlp': False, 'add_source': True, 'cgnn': False, 'time': 18.294754260552843, 'augment': False, 'method': 'dopri5', 'step_size': 1, 'max_iters': 100, 'adjoint_method': 'adaptive_heun', 'adjoint': False, 'adjoint_step_size': 1, 'tol_scale': 821.9773048827274, 'tol_scale_adjoint': 1.0, 'ode_blocks': 1, 'max_nfe': 2000, 'no_early': False, 'earlystopxT': 3, 'max_test_steps': 100, 'leaky_relu_slope': 0.2, 'attention_dropout': 0.0, 'heads': 8, 'attention_norm_idx': 1, 'attention_dim': 128, 'mix_features': False, 'reweight_attention': False, 'attention_type': 'scaled_dot', 'square_plus': True, 'jacobian_norm2': None, 'total_deriv': None, 'kinetic_energy': None, 'directional_penalty': None, 'not_lcc': True, 'rewiring': None, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_k': 64, 'gdc_threshold': 0.01, 'gdc_avg_degree': 64, 'ppr_alpha': 0.05, 'heat_time': 3.0, 'att_samp_pct': 1, 'use_flux': False, 'exact': True, 'M_nodes': 64, 'new_edges': 'random', 'sparsify': 'S_hat', 'threshold_type': 'addD_rvR', 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'KNN_online': False, 'KNN_online_reps': 4, 'KNN_space': 'pos_distance', 'beltrami': False, 'fa_layer': False, 'pos_enc_type': 'GDC', 'pos_enc_orientation': 'row', 'feat_hidden_dim': 64, 'pos_enc_hidden_dim': 16, 'edge_sampling': False, 'edge_sampling_T': 'T0', 'edge_sampling_epoch': 5, 'edge_sampling_add': 0.64, 'edge_sampling_add_type': 'importance', 'edge_sampling_rmv': 0.32, 'edge_sampling_sym': False, 'edge_sampling_online': False, 'edge_sampling_online_reps': 4, 'edge_sampling_space': 'attention', 'symmetric_attention': False, 'fa_layer_edge_sampling_rmv': 0.8, 'gpu': 0, 'pos_enc_csv': False, 'pos_dist_quantile': 0.001, 'count': '4', 'seed': 2023, 'adaptive': False, 'attention_rewiring': False, 'baseline': False, 'cpus': 1, 'dt': 0.001, 'dt_min': 1e-05, 'gpus': 0.5, 'grace_period': 20, 'max_epochs': 1000, 'metric': 'accuracy', 'name': 'cora_beltrami_splits', 'num_init': 1, 'num_samples': 1000, 'patience': 100, 'reduction_factor': 10, 'regularise': False, 'use_lcc': True}
2023/08/10 06:06:42 PM Epoch: 001, Runtime 453.726315, Loss 1.950008, forward nfe 50, backward nfe 0, Train: 0.7071, Val: 0.5640, Test: 0.5645, Best time: 5.6214
2023/08/10 06:15:05 PM Epoch: 002, Runtime 502.900077, Loss 1.836955, forward nfe 228, backward nfe 0, Train: 0.8643, Val: 0.7882, Test: 0.7726, Best time: 5.8392
2023/08/10 06:23:32 PM Epoch: 003, Runtime 506.873934, Loss 1.646724, forward nfe 406, backward nfe 0, Train: 0.8643, Val: 0.7882, Test: 0.7726, Best time: 18.2948
2023/08/10 06:31:58 PM Epoch: 004, Runtime 505.768769, Loss 1.432867, forward nfe 584, backward nfe 0, Train: 0.8643, Val: 0.7882, Test: 0.7726, Best time: 18.2948
2023/08/10 06:40:27 PM Epoch: 005, Runtime 509.753438, Loss 1.195104, forward nfe 762, backward nfe 0, Train: 0.8786, Val: 0.7897, Test: 0.7838, Best time: 5.9393
2023/08/10 06:48:44 PM Epoch: 006, Runtime 496.614346, Loss 0.955793, forward nfe 940, backward nfe 0, Train: 0.8929, Val: 0.7956, Test: 0.7827, Best time: 6.1112
2023/08/10 06:57:02 PM Epoch: 007, Runtime 497.523035, Loss 0.754784, forward nfe 1112, backward nfe 0, Train: 0.9214, Val: 0.8007, Test: 0.7878, Best time: 8.7685
2023/08/10 07:04:53 PM Epoch: 008, Runtime 471.341487, Loss 0.573617, forward nfe 1278, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7970, Best time: 8.9951
2023/08/10 07:12:45 PM Epoch: 009, Runtime 471.961903, Loss 0.488263, forward nfe 1444, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8244, Best time: 31.8241
2023/08/10 07:20:35 PM Epoch: 010, Runtime 470.482582, Loss 0.357299, forward nfe 1610, backward nfe 0, Train: 0.9571, Val: 0.8213, Test: 0.8102, Best time: 18.7526
2023/08/10 07:28:28 PM Epoch: 011, Runtime 472.566000, Loss 0.317536, forward nfe 1776, backward nfe 0, Train: 0.9571, Val: 0.8213, Test: 0.8102, Best time: 18.2948
2023/08/10 07:36:30 PM Epoch: 012, Runtime 482.282063, Loss 0.263466, forward nfe 1942, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 15.4660
2023/08/10 07:44:33 PM Epoch: 013, Runtime 482.393570, Loss 0.227104, forward nfe 2108, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 07:52:36 PM Epoch: 014, Runtime 483.119590, Loss 0.188156, forward nfe 2274, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:00:39 PM Epoch: 015, Runtime 483.282492, Loss 0.202505, forward nfe 2440, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:08:44 PM Epoch: 016, Runtime 484.790694, Loss 0.159988, forward nfe 2606, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:16:49 PM Epoch: 017, Runtime 484.901957, Loss 0.160217, forward nfe 2772, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:24:53 PM Epoch: 018, Runtime 484.663754, Loss 0.150505, forward nfe 2938, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:32:53 PM Epoch: 019, Runtime 479.350307, Loss 0.139179, forward nfe 3104, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:40:56 PM Epoch: 020, Runtime 483.626524, Loss 0.153360, forward nfe 3264, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:48:54 PM Epoch: 021, Runtime 477.964602, Loss 0.143523, forward nfe 3424, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 08:57:01 PM Epoch: 022, Runtime 487.092147, Loss 0.147170, forward nfe 3584, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 09:05:15 PM Epoch: 023, Runtime 493.411239, Loss 0.153922, forward nfe 3744, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 09:13:47 PM Epoch: 024, Runtime 512.071766, Loss 0.117023, forward nfe 3904, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
2023/08/10 09:23:13 PM Epoch: 025, Runtime 565.615866, Loss 0.120980, forward nfe 4064, backward nfe 0, Train: 0.9786, Val: 0.8257, Test: 0.8132, Best time: 18.2948
