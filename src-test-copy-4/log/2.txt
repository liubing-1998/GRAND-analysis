ax = self.anisotropic_diffusion_g_without_distance(x)
if not self.opt['no_alpha_sigmoid']:
  alpha = torch.sigmoid(self.alpha_train)
else:
  alpha = self.alpha_train
f = alpha * ax

2023/08/10 10:09:02 AM {'use_cora_defaults': False, 'dataset': 'Cora', 'data_norm': 'rw', 'self_loop_weight': 1.0, 'use_labels': False, 'geom_gcn_splits': False, 'num_splits': 2, 'label_rate': 0.5, 'planetoid_split': False, 'hidden_dim': 80, 'fc_out': False, 'input_dropout': 0.5, 'dropout': 0.046878964627763316, 'batch_norm': False, 'optimizer': 'adamax', 'lr': 0.022924849756740397, 'decay': 0.00507685443154266, 'epoch': 100, 'alpha': 1.0, 'alpha_dim': 'sc', 'no_alpha_sigmoid': False, 'beta_dim': 'sc', 'block': 'constant', 'function': 'laplacian', 'use_mlp': False, 'add_source': True, 'cgnn': False, 'time': 18.294754260552843, 'augment': False, 'method': 'dopri5', 'step_size': 1, 'max_iters': 100, 'adjoint_method': 'adaptive_heun', 'adjoint': False, 'adjoint_step_size': 1, 'tol_scale': 821.9773048827274, 'tol_scale_adjoint': 1.0, 'ode_blocks': 1, 'max_nfe': 2000, 'no_early': False, 'earlystopxT': 3, 'max_test_steps': 100, 'leaky_relu_slope': 0.2, 'attention_dropout': 0.0, 'heads': 8, 'attention_norm_idx': 1, 'attention_dim': 128, 'mix_features': False, 'reweight_attention': False, 'attention_type': 'scaled_dot', 'square_plus': True, 'jacobian_norm2': None, 'total_deriv': None, 'kinetic_energy': None, 'directional_penalty': None, 'not_lcc': True, 'rewiring': None, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_k': 64, 'gdc_threshold': 0.01, 'gdc_avg_degree': 64, 'ppr_alpha': 0.05, 'heat_time': 3.0, 'att_samp_pct': 1, 'use_flux': False, 'exact': True, 'M_nodes': 64, 'new_edges': 'random', 'sparsify': 'S_hat', 'threshold_type': 'addD_rvR', 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'KNN_online': False, 'KNN_online_reps': 4, 'KNN_space': 'pos_distance', 'beltrami': False, 'fa_layer': False, 'pos_enc_type': 'GDC', 'pos_enc_orientation': 'row', 'feat_hidden_dim': 64, 'pos_enc_hidden_dim': 16, 'edge_sampling': False, 'edge_sampling_T': 'T0', 'edge_sampling_epoch': 5, 'edge_sampling_add': 0.64, 'edge_sampling_add_type': 'importance', 'edge_sampling_rmv': 0.32, 'edge_sampling_sym': False, 'edge_sampling_online': False, 'edge_sampling_online_reps': 4, 'edge_sampling_space': 'attention', 'symmetric_attention': False, 'fa_layer_edge_sampling_rmv': 0.8, 'gpu': 0, 'pos_enc_csv': False, 'pos_dist_quantile': 0.001, 'count': '2', 'seed': 2023, 'adaptive': False, 'attention_rewiring': False, 'baseline': False, 'cpus': 1, 'dt': 0.001, 'dt_min': 1e-05, 'gpus': 0.5, 'grace_period': 20, 'max_epochs': 1000, 'metric': 'accuracy', 'name': 'cora_beltrami_splits', 'num_init': 1, 'num_samples': 1000, 'patience': 100, 'reduction_factor': 10, 'regularise': False, 'use_lcc': True}
2023/08/10 10:14:23 AM Epoch: 001, Runtime 320.515034, Loss 1.949947, forward nfe 50, backward nfe 0, Train: 0.6714, Val: 0.5257, Test: 0.5198, Best time: 2.8979
2023/08/10 10:20:02 AM Epoch: 002, Runtime 339.691473, Loss 1.838298, forward nfe 216, backward nfe 0, Train: 0.8571, Val: 0.7765, Test: 0.7695, Best time: 6.7022
2023/08/10 10:25:37 AM Epoch: 003, Runtime 334.594549, Loss 1.661366, forward nfe 388, backward nfe 0, Train: 0.8714, Val: 0.7816, Test: 0.7624, Best time: 2.6867
2023/08/10 10:31:07 AM Epoch: 004, Runtime 329.798571, Loss 1.475206, forward nfe 566, backward nfe 0, Train: 0.8714, Val: 0.7816, Test: 0.7624, Best time: 18.2948
2023/08/10 10:36:51 AM Epoch: 005, Runtime 344.604440, Loss 1.284234, forward nfe 732, backward nfe 0, Train: 0.8857, Val: 0.7824, Test: 0.7685, Best time: 2.5684
2023/08/10 10:42:12 AM Epoch: 006, Runtime 320.694537, Loss 1.077558, forward nfe 904, backward nfe 0, Train: 0.8857, Val: 0.7824, Test: 0.7685, Best time: 18.2948
2023/08/10 10:47:57 AM Epoch: 007, Runtime 344.534357, Loss 0.895296, forward nfe 1082, backward nfe 0, Train: 0.8643, Val: 0.7934, Test: 0.7858, Best time: 5.9724
2023/08/10 10:53:41 AM Epoch: 008, Runtime 344.435997, Loss 0.755989, forward nfe 1266, backward nfe 0, Train: 0.8643, Val: 0.8037, Test: 0.7990, Best time: 5.9150
2023/08/10 10:59:28 AM Epoch: 009, Runtime 346.997767, Loss 0.638221, forward nfe 1450, backward nfe 0, Train: 0.9071, Val: 0.8140, Test: 0.8010, Best time: 5.8821
2023/08/10 11:05:13 AM Epoch: 010, Runtime 344.772885, Loss 0.533165, forward nfe 1634, backward nfe 0, Train: 0.9143, Val: 0.8162, Test: 0.8081, Best time: 5.8709
2023/08/10 11:10:59 AM Epoch: 011, Runtime 345.654633, Loss 0.480283, forward nfe 1818, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 8.0988
2023/08/10 11:16:36 AM Epoch: 012, Runtime 337.532223, Loss 0.431301, forward nfe 2002, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:22:15 AM Epoch: 013, Runtime 338.718268, Loss 0.387501, forward nfe 2180, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:27:58 AM Epoch: 014, Runtime 342.743090, Loss 0.381269, forward nfe 2358, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:33:43 AM Epoch: 015, Runtime 345.629507, Loss 0.367033, forward nfe 2536, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:39:23 AM Epoch: 016, Runtime 340.196118, Loss 0.333744, forward nfe 2714, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:45:05 AM Epoch: 017, Runtime 341.973231, Loss 0.318988, forward nfe 2892, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:50:46 AM Epoch: 018, Runtime 340.962089, Loss 0.321992, forward nfe 3070, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 11:56:29 AM Epoch: 019, Runtime 343.146139, Loss 0.308159, forward nfe 3248, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:02:14 PM Epoch: 020, Runtime 344.980339, Loss 0.292072, forward nfe 3426, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:07:33 PM Epoch: 021, Runtime 318.576748, Loss 0.286747, forward nfe 3598, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:12:53 PM Epoch: 022, Runtime 319.506410, Loss 0.300324, forward nfe 3764, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:18:13 PM Epoch: 023, Runtime 320.467615, Loss 0.282978, forward nfe 3930, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:23:33 PM Epoch: 024, Runtime 320.075343, Loss 0.261925, forward nfe 4096, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:28:49 PM Epoch: 025, Runtime 316.004625, Loss 0.258984, forward nfe 4262, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:34:04 PM Epoch: 026, Runtime 315.208592, Loss 0.278725, forward nfe 4428, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:39:35 PM Epoch: 027, Runtime 330.243084, Loss 0.251355, forward nfe 4594, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:44:35 PM Epoch: 028, Runtime 300.485757, Loss 0.249626, forward nfe 4760, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:49:37 PM Epoch: 029, Runtime 302.457375, Loss 0.269283, forward nfe 4914, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:54:43 PM Epoch: 030, Runtime 305.664117, Loss 0.254153, forward nfe 5068, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 12:59:43 PM Epoch: 031, Runtime 299.463779, Loss 0.247205, forward nfe 5222, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 01:04:47 PM Epoch: 032, Runtime 304.094790, Loss 0.244062, forward nfe 5376, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 01:10:12 PM Epoch: 033, Runtime 325.626611, Loss 0.217288, forward nfe 5530, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 01:15:53 PM Epoch: 034, Runtime 341.131800, Loss 0.227637, forward nfe 5690, backward nfe 0, Train: 0.9143, Val: 0.8199, Test: 0.8162, Best time: 18.2948
2023/08/10 01:21:36 PM Epoch: 035, Runtime 342.641801, Loss 0.215076, forward nfe 5850, backward nfe 0, Train: 0.9714, Val: 0.8206, Test: 0.8030, Best time: 10.8149
2023/08/10 01:27:04 PM Epoch: 036, Runtime 328.033165, Loss 0.212880, forward nfe 6010, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 10.9533
2023/08/10 01:31:58 PM Epoch: 037, Runtime 293.463791, Loss 0.224932, forward nfe 6170, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 01:36:51 PM Epoch: 038, Runtime 293.468893, Loss 0.212839, forward nfe 6318, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 01:41:47 PM Epoch: 039, Runtime 296.151906, Loss 0.211180, forward nfe 6466, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 01:46:38 PM Epoch: 040, Runtime 291.189404, Loss 0.208705, forward nfe 6614, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 01:51:21 PM Epoch: 041, Runtime 282.240657, Loss 0.192183, forward nfe 6756, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 01:56:07 PM Epoch: 042, Runtime 286.487394, Loss 0.193652, forward nfe 6898, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:00:56 PM Epoch: 043, Runtime 288.432058, Loss 0.191019, forward nfe 7040, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:05:48 PM Epoch: 044, Runtime 292.088323, Loss 0.175195, forward nfe 7182, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:10:32 PM Epoch: 045, Runtime 284.451466, Loss 0.187584, forward nfe 7324, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:15:04 PM Epoch: 046, Runtime 271.680138, Loss 0.193178, forward nfe 7466, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:19:37 PM Epoch: 047, Runtime 273.092171, Loss 0.178415, forward nfe 7602, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:24:14 PM Epoch: 048, Runtime 276.948512, Loss 0.156090, forward nfe 7738, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:28:51 PM Epoch: 049, Runtime 277.504614, Loss 0.212169, forward nfe 7874, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:33:19 PM Epoch: 050, Runtime 267.888354, Loss 0.177671, forward nfe 8010, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:37:48 PM Epoch: 051, Runtime 268.854169, Loss 0.174582, forward nfe 8146, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:42:18 PM Epoch: 052, Runtime 270.220091, Loss 0.165731, forward nfe 8282, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:46:49 PM Epoch: 053, Runtime 270.444879, Loss 0.160101, forward nfe 8418, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:51:19 PM Epoch: 054, Runtime 270.406743, Loss 0.170206, forward nfe 8554, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 02:55:45 PM Epoch: 055, Runtime 266.146736, Loss 0.154122, forward nfe 8690, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:00:13 PM Epoch: 056, Runtime 267.642081, Loss 0.160139, forward nfe 8826, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:04:19 PM Epoch: 057, Runtime 246.372597, Loss 0.148610, forward nfe 8962, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:08:25 PM Epoch: 058, Runtime 245.470483, Loss 0.168576, forward nfe 9086, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:12:31 PM Epoch: 059, Runtime 245.765562, Loss 0.140736, forward nfe 9210, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:16:36 PM Epoch: 060, Runtime 245.065803, Loss 0.142006, forward nfe 9334, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:20:25 PM Epoch: 061, Runtime 229.270529, Loss 0.141820, forward nfe 9452, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:24:14 PM Epoch: 062, Runtime 228.991908, Loss 0.125061, forward nfe 9570, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:28:06 PM Epoch: 063, Runtime 231.681455, Loss 0.133967, forward nfe 9688, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:31:58 PM Epoch: 064, Runtime 232.400164, Loss 0.140986, forward nfe 9806, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:35:50 PM Epoch: 065, Runtime 232.362166, Loss 0.136095, forward nfe 9924, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:39:42 PM Epoch: 066, Runtime 231.204233, Loss 0.136744, forward nfe 10042, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:43:32 PM Epoch: 067, Runtime 230.346933, Loss 0.139951, forward nfe 10160, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:47:23 PM Epoch: 068, Runtime 231.588196, Loss 0.130433, forward nfe 10278, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:51:15 PM Epoch: 069, Runtime 231.561891, Loss 0.119461, forward nfe 10396, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:54:48 PM Epoch: 070, Runtime 213.077037, Loss 0.121772, forward nfe 10514, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 03:58:22 PM Epoch: 071, Runtime 214.118335, Loss 0.127425, forward nfe 10620, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:01:54 PM Epoch: 072, Runtime 211.741344, Loss 0.103133, forward nfe 10726, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:05:26 PM Epoch: 073, Runtime 211.911510, Loss 0.126984, forward nfe 10832, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:08:58 PM Epoch: 074, Runtime 211.623946, Loss 0.129963, forward nfe 10938, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:12:29 PM Epoch: 075, Runtime 211.752920, Loss 0.138547, forward nfe 11044, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:16:01 PM Epoch: 076, Runtime 211.243937, Loss 0.135120, forward nfe 11150, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:19:31 PM Epoch: 077, Runtime 210.512164, Loss 0.133690, forward nfe 11256, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:23:02 PM Epoch: 078, Runtime 210.675607, Loss 0.108311, forward nfe 11362, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:26:34 PM Epoch: 079, Runtime 212.331120, Loss 0.104694, forward nfe 11468, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:30:07 PM Epoch: 080, Runtime 212.489189, Loss 0.107947, forward nfe 11574, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:33:38 PM Epoch: 081, Runtime 211.108413, Loss 0.111317, forward nfe 11680, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:37:08 PM Epoch: 082, Runtime 210.863822, Loss 0.121277, forward nfe 11786, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:40:24 PM Epoch: 083, Runtime 195.256165, Loss 0.096881, forward nfe 11886, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:43:40 PM Epoch: 084, Runtime 195.822195, Loss 0.096921, forward nfe 11986, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:46:56 PM Epoch: 085, Runtime 196.576348, Loss 0.106051, forward nfe 12086, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:50:13 PM Epoch: 086, Runtime 196.427085, Loss 0.114631, forward nfe 12186, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:53:28 PM Epoch: 087, Runtime 195.631147, Loss 0.100628, forward nfe 12286, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 04:56:44 PM Epoch: 088, Runtime 195.547025, Loss 0.101712, forward nfe 12386, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:00:00 PM Epoch: 089, Runtime 196.526103, Loss 0.094692, forward nfe 12486, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:03:16 PM Epoch: 090, Runtime 195.503679, Loss 0.105740, forward nfe 12586, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:06:32 PM Epoch: 091, Runtime 195.876985, Loss 0.116699, forward nfe 12686, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:09:38 PM Epoch: 092, Runtime 186.024657, Loss 0.098573, forward nfe 12786, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:12:45 PM Epoch: 093, Runtime 187.296137, Loss 0.099721, forward nfe 12880, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:15:52 PM Epoch: 094, Runtime 186.975317, Loss 0.106405, forward nfe 12974, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:18:59 PM Epoch: 095, Runtime 186.946535, Loss 0.102313, forward nfe 13068, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:22:06 PM Epoch: 096, Runtime 186.964571, Loss 0.091630, forward nfe 13162, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:25:12 PM Epoch: 097, Runtime 185.946809, Loss 0.101126, forward nfe 13256, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:28:19 PM Epoch: 098, Runtime 186.762766, Loss 0.114761, forward nfe 13350, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:31:25 PM Epoch: 099, Runtime 186.174402, Loss 0.103332, forward nfe 13444, backward nfe 0, Train: 1.0000, Val: 0.8221, Test: 0.8081, Best time: 18.2948
2023/08/10 05:31:25 PM best val accuracy 0.822059 with test accuracy 0.808122 at epoch 36 and best time 18.294754
