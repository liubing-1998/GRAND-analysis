# origin code
ax = self.sparse_multiply(x)  # shape=(2485, 80)
if not self.opt['no_alpha_sigmoid']:
  alpha = torch.sigmoid(self.alpha_train)
else:
  alpha = self.alpha_train

f = alpha * (ax - x)
if self.opt['add_source']:
  f = f + self.beta_train * self.x0


2023/08/10 09:53:00 AM {'use_cora_defaults': False, 'dataset': 'Cora', 'data_norm': 'rw', 'self_loop_weight': 1.0, 'use_labels': False, 'geom_gcn_splits': False, 'num_splits': 2, 'label_rate': 0.5, 'planetoid_split': False, 'hidden_dim': 80, 'fc_out': False, 'input_dropout': 0.5, 'dropout': 0.046878964627763316, 'batch_norm': False, 'optimizer': 'adamax', 'lr': 0.022924849756740397, 'decay': 0.00507685443154266, 'epoch': 100, 'alpha': 1.0, 'alpha_dim': 'sc', 'no_alpha_sigmoid': False, 'beta_dim': 'sc', 'block': 'constant', 'function': 'laplacian', 'use_mlp': False, 'add_source': True, 'cgnn': False, 'time': 18.294754260552843, 'augment': False, 'method': 'dopri5', 'step_size': 1, 'max_iters': 100, 'adjoint_method': 'adaptive_heun', 'adjoint': False, 'adjoint_step_size': 1, 'tol_scale': 821.9773048827274, 'tol_scale_adjoint': 1.0, 'ode_blocks': 1, 'max_nfe': 2000, 'no_early': False, 'earlystopxT': 3, 'max_test_steps': 100, 'leaky_relu_slope': 0.2, 'attention_dropout': 0.0, 'heads': 8, 'attention_norm_idx': 1, 'attention_dim': 128, 'mix_features': False, 'reweight_attention': False, 'attention_type': 'scaled_dot', 'square_plus': True, 'jacobian_norm2': None, 'total_deriv': None, 'kinetic_energy': None, 'directional_penalty': None, 'not_lcc': True, 'rewiring': None, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_k': 64, 'gdc_threshold': 0.01, 'gdc_avg_degree': 64, 'ppr_alpha': 0.05, 'heat_time': 3.0, 'att_samp_pct': 1, 'use_flux': False, 'exact': True, 'M_nodes': 64, 'new_edges': 'random', 'sparsify': 'S_hat', 'threshold_type': 'addD_rvR', 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'KNN_online': False, 'KNN_online_reps': 4, 'KNN_space': 'pos_distance', 'beltrami': False, 'fa_layer': False, 'pos_enc_type': 'GDC', 'pos_enc_orientation': 'row', 'feat_hidden_dim': 64, 'pos_enc_hidden_dim': 16, 'edge_sampling': False, 'edge_sampling_T': 'T0', 'edge_sampling_epoch': 5, 'edge_sampling_add': 0.64, 'edge_sampling_add_type': 'importance', 'edge_sampling_rmv': 0.32, 'edge_sampling_sym': False, 'edge_sampling_online': False, 'edge_sampling_online_reps': 4, 'edge_sampling_space': 'attention', 'symmetric_attention': False, 'fa_layer_edge_sampling_rmv': 0.8, 'gpu': 0, 'pos_enc_csv': False, 'pos_dist_quantile': 0.001, 'count': '1', 'adaptive': False, 'attention_rewiring': False, 'baseline': False, 'cpus': 1, 'dt': 0.001, 'dt_min': 1e-05, 'gpus': 0.5, 'grace_period': 20, 'max_epochs': 1000, 'metric': 'accuracy', 'name': 'cora_beltrami_splits', 'num_init': 1, 'num_samples': 1000, 'patience': 100, 'reduction_factor': 10, 'regularise': False, 'use_lcc': True}
2023/08/10 09:53:02 AM Epoch: 001, Runtime 1.889219, Loss 1.948078, forward nfe 50, backward nfe 0, Train: 0.5286, Val: 0.3662, Test: 0.3503, Best time: 1.0474
2023/08/10 09:53:03 AM Epoch: 002, Runtime 0.270254, Loss 1.819683, forward nfe 228, backward nfe 0, Train: 0.6643, Val: 0.4691, Test: 0.4904, Best time: 0.9924
2023/08/10 09:53:03 AM Epoch: 003, Runtime 0.216046, Loss 1.562054, forward nfe 418, backward nfe 0, Train: 0.8714, Val: 0.7544, Test: 0.7381, Best time: 16.1024
2023/08/10 09:53:03 AM Epoch: 004, Runtime 0.216056, Loss 1.267053, forward nfe 596, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.8030, Best time: 15.7185
2023/08/10 09:53:03 AM Epoch: 005, Runtime 0.238771, Loss 0.974514, forward nfe 780, backward nfe 0, Train: 0.9214, Val: 0.8184, Test: 0.8162, Best time: 15.5440
2023/08/10 09:53:03 AM Epoch: 006, Runtime 0.263925, Loss 0.739305, forward nfe 964, backward nfe 0, Train: 0.9214, Val: 0.8221, Test: 0.8254, Best time: 11.9260
2023/08/10 09:53:04 AM Epoch: 007, Runtime 0.229559, Loss 0.534395, forward nfe 1142, backward nfe 0, Train: 0.9214, Val: 0.8221, Test: 0.8254, Best time: 18.2948
2023/08/10 09:53:04 AM Epoch: 008, Runtime 0.304047, Loss 0.397992, forward nfe 1320, backward nfe 0, Train: 0.9214, Val: 0.8221, Test: 0.8254, Best time: 18.2948
2023/08/10 09:53:04 AM Epoch: 009, Runtime 0.298404, Loss 0.321517, forward nfe 1498, backward nfe 0, Train: 0.9214, Val: 0.8221, Test: 0.8254, Best time: 18.2948
2023/08/10 09:53:05 AM Epoch: 010, Runtime 0.452532, Loss 0.265591, forward nfe 1676, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 33.0329
2023/08/10 09:53:05 AM Epoch: 011, Runtime 0.316389, Loss 0.222226, forward nfe 1854, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:05 AM Epoch: 012, Runtime 0.361061, Loss 0.191023, forward nfe 2038, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:06 AM Epoch: 013, Runtime 0.305627, Loss 0.182786, forward nfe 2222, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:06 AM Epoch: 014, Runtime 0.489214, Loss 0.183191, forward nfe 2406, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:07 AM Epoch: 015, Runtime 0.316743, Loss 0.168839, forward nfe 2572, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:07 AM Epoch: 016, Runtime 0.288366, Loss 0.162362, forward nfe 2738, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:07 AM Epoch: 017, Runtime 0.321666, Loss 0.174473, forward nfe 2904, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:08 AM Epoch: 018, Runtime 0.436171, Loss 0.175739, forward nfe 3070, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:08 AM Epoch: 019, Runtime 0.301182, Loss 0.171499, forward nfe 3236, backward nfe 0, Train: 0.9500, Val: 0.8390, Test: 0.8376, Best time: 18.2948
2023/08/10 09:53:08 AM Epoch: 020, Runtime 0.346244, Loss 0.171911, forward nfe 3402, backward nfe 0, Train: 0.9714, Val: 0.8441, Test: 0.8335, Best time: 33.4993
2023/08/10 09:53:09 AM Epoch: 021, Runtime 0.298680, Loss 0.156079, forward nfe 3574, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 33.9102
2023/08/10 09:53:09 AM Epoch: 022, Runtime 0.365623, Loss 0.167285, forward nfe 3746, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:09 AM Epoch: 023, Runtime 0.292764, Loss 0.190387, forward nfe 3912, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:10 AM Epoch: 024, Runtime 0.341383, Loss 0.174336, forward nfe 4078, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:10 AM Epoch: 025, Runtime 0.262064, Loss 0.129987, forward nfe 4244, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:10 AM Epoch: 026, Runtime 0.212599, Loss 0.198936, forward nfe 4410, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:10 AM Epoch: 027, Runtime 0.294401, Loss 0.131690, forward nfe 4570, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:10 AM Epoch: 028, Runtime 0.207353, Loss 0.170907, forward nfe 4730, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:11 AM Epoch: 029, Runtime 0.168749, Loss 0.136116, forward nfe 4890, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:11 AM Epoch: 030, Runtime 0.217118, Loss 0.138370, forward nfe 5050, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:11 AM Epoch: 031, Runtime 0.165037, Loss 0.129492, forward nfe 5210, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:11 AM Epoch: 032, Runtime 0.183348, Loss 0.207227, forward nfe 5364, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:11 AM Epoch: 033, Runtime 0.185128, Loss 0.143916, forward nfe 5518, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:12 AM Epoch: 034, Runtime 0.206978, Loss 0.134678, forward nfe 5672, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:12 AM Epoch: 035, Runtime 0.234854, Loss 0.109852, forward nfe 5826, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:12 AM Epoch: 036, Runtime 0.179119, Loss 0.137944, forward nfe 5980, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:12 AM Epoch: 037, Runtime 0.175287, Loss 0.113755, forward nfe 6134, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:12 AM Epoch: 038, Runtime 0.159000, Loss 0.129975, forward nfe 6288, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:13 AM Epoch: 039, Runtime 0.186110, Loss 0.126930, forward nfe 6442, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:13 AM Epoch: 040, Runtime 0.158784, Loss 0.135600, forward nfe 6596, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:13 AM Epoch: 041, Runtime 0.158642, Loss 0.113950, forward nfe 6750, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:13 AM Epoch: 042, Runtime 0.217099, Loss 0.114994, forward nfe 6904, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:13 AM Epoch: 043, Runtime 0.163076, Loss 0.121399, forward nfe 7058, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 044, Runtime 0.264402, Loss 0.118450, forward nfe 7206, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 045, Runtime 0.191573, Loss 0.102290, forward nfe 7354, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 046, Runtime 0.230174, Loss 0.106714, forward nfe 7502, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 047, Runtime 0.158051, Loss 0.124173, forward nfe 7650, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 048, Runtime 0.208521, Loss 0.103932, forward nfe 7804, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:14 AM Epoch: 049, Runtime 0.158450, Loss 0.106290, forward nfe 7958, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:15 AM Epoch: 050, Runtime 0.221001, Loss 0.105541, forward nfe 8112, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:15 AM Epoch: 051, Runtime 0.266438, Loss 0.108211, forward nfe 8266, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:15 AM Epoch: 052, Runtime 0.168483, Loss 0.120598, forward nfe 8420, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:15 AM Epoch: 053, Runtime 0.260954, Loss 0.132769, forward nfe 8574, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:16 AM Epoch: 054, Runtime 0.216341, Loss 0.090859, forward nfe 8728, backward nfe 0, Train: 0.9714, Val: 0.8463, Test: 0.8294, Best time: 18.2948
2023/08/10 09:53:16 AM Epoch: 055, Runtime 0.158116, Loss 0.117788, forward nfe 8882, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 40.2684
2023/08/10 09:53:16 AM Epoch: 056, Runtime 0.197659, Loss 0.094198, forward nfe 9036, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:16 AM Epoch: 057, Runtime 0.158118, Loss 0.111023, forward nfe 9190, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:16 AM Epoch: 058, Runtime 0.156042, Loss 0.116868, forward nfe 9344, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:16 AM Epoch: 059, Runtime 0.212953, Loss 0.123155, forward nfe 9498, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:17 AM Epoch: 060, Runtime 0.253223, Loss 0.110895, forward nfe 9652, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:17 AM Epoch: 061, Runtime 0.238200, Loss 0.137608, forward nfe 9806, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:17 AM Epoch: 062, Runtime 0.173494, Loss 0.158259, forward nfe 9960, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:17 AM Epoch: 063, Runtime 0.253932, Loss 0.074145, forward nfe 10108, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:18 AM Epoch: 064, Runtime 0.155005, Loss 0.116817, forward nfe 10256, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:18 AM Epoch: 065, Runtime 0.152209, Loss 0.109284, forward nfe 10404, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:18 AM Epoch: 066, Runtime 0.215289, Loss 0.133181, forward nfe 10552, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:18 AM Epoch: 067, Runtime 0.227966, Loss 0.079052, forward nfe 10700, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:18 AM Epoch: 068, Runtime 0.150999, Loss 0.090390, forward nfe 10848, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 069, Runtime 0.220777, Loss 0.121417, forward nfe 10996, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 070, Runtime 0.231895, Loss 0.081458, forward nfe 11144, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 071, Runtime 0.152708, Loss 0.092932, forward nfe 11292, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 072, Runtime 0.153995, Loss 0.092933, forward nfe 11440, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 073, Runtime 0.153172, Loss 0.129666, forward nfe 11588, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:19 AM Epoch: 074, Runtime 0.202063, Loss 0.107654, forward nfe 11736, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:20 AM Epoch: 075, Runtime 0.232894, Loss 0.089827, forward nfe 11878, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:20 AM Epoch: 076, Runtime 0.166000, Loss 0.088768, forward nfe 12014, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:20 AM Epoch: 077, Runtime 0.195276, Loss 0.084004, forward nfe 12150, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:20 AM Epoch: 078, Runtime 0.203717, Loss 0.093677, forward nfe 12286, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:20 AM Epoch: 079, Runtime 0.139793, Loss 0.083061, forward nfe 12422, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 080, Runtime 0.152544, Loss 0.132106, forward nfe 12558, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 081, Runtime 0.141093, Loss 0.073656, forward nfe 12694, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 082, Runtime 0.157885, Loss 0.096442, forward nfe 12830, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 083, Runtime 0.170192, Loss 0.075339, forward nfe 12966, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 084, Runtime 0.142986, Loss 0.090780, forward nfe 13102, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 085, Runtime 0.143667, Loss 0.109920, forward nfe 13238, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:21 AM Epoch: 086, Runtime 0.139521, Loss 0.110448, forward nfe 13374, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 087, Runtime 0.176891, Loss 0.091430, forward nfe 13510, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 088, Runtime 0.158338, Loss 0.093874, forward nfe 13646, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 089, Runtime 0.206463, Loss 0.098768, forward nfe 13782, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 090, Runtime 0.197333, Loss 0.090944, forward nfe 13918, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 091, Runtime 0.159102, Loss 0.085209, forward nfe 14054, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:22 AM Epoch: 092, Runtime 0.147001, Loss 0.094615, forward nfe 14190, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:23 AM Epoch: 093, Runtime 0.248312, Loss 0.092831, forward nfe 14326, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:23 AM Epoch: 094, Runtime 0.166045, Loss 0.113651, forward nfe 14462, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:23 AM Epoch: 095, Runtime 0.146135, Loss 0.108913, forward nfe 14598, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:23 AM Epoch: 096, Runtime 0.200123, Loss 0.101968, forward nfe 14740, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:23 AM Epoch: 097, Runtime 0.146042, Loss 0.087343, forward nfe 14882, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:24 AM Epoch: 098, Runtime 0.188828, Loss 0.077882, forward nfe 15024, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:24 AM Epoch: 099, Runtime 0.242078, Loss 0.087650, forward nfe 15166, backward nfe 0, Train: 0.9857, Val: 0.8485, Test: 0.8386, Best time: 18.2948
2023/08/10 09:53:24 AM best val accuracy 0.848529 with test accuracy 0.838579 at epoch 55 and best time 18.294754
